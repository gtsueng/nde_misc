{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c08bbafa",
   "metadata": {},
   "source": [
    "# Testing the EXTRACT API for basic NER\n",
    "\n",
    "\n",
    "The EXTRACT tool and API documentation\n",
    "https://extract.jensenlab.org/\n",
    "\n",
    "**GetEntities**\n",
    "\n",
    "GetEntities (http://tagger.jensenlab.org/GetEntities) returns the unique list of the entities identified in the document. The entities belong to the specified entity_types and the response follows the specified format.\n",
    "\n",
    "Request:\n",
    "```\n",
    "http://tagger.jensenlab.org/GetEntities?document=Both+samples+were+dominated+by+Zetaproteobacteria+Fe+oxidizers.+This+group+was+most+abundant+at+Volcano+1,+where+sediments+were+richer+in+Fe+and+contained+more+crystalline+forms+of+Fe+oxides.&entity_types=-2+-25+-26+-27&format=tsv\n",
    "```\n",
    "Response:\n",
    "```\n",
    "Zetaproteobacteria\t-2\t580370\n",
    "sediments\t-27\tENVO:00002007\n",
    "Volcano\t-27\tENVO:00000247\n",
    "```\n",
    "\n",
    "Note: HTTPS is also supported (use https://tagger.jensenlab.org/)\n",
    "\n",
    "**Parameters:**\n",
    "\n",
    "document: the plain or html-formatted text to be tagged\n",
    "\n",
    "format: \"tsv\" or \"xml\" (default)\n",
    "\n",
    "Entity types to fetch:\n",
    "-2: NCBI Taxonomy entries\n",
    "-26: Disease Ontology terms\n",
    "(concatenate with \"+\" to use multiple) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb399267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "import math\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e870194",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set filepaths\n",
    "script_path = os.getcwd()\n",
    "parent_path = os.path.dirname(script_path)\n",
    "input_path = os.path.join(parent_path,'Pubtator_Check','data')\n",
    "input_file = os.path.join(input_path,'unnannotated_records.tsv')\n",
    "output_path = os.path.join(script_path,'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f23164f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tsv(ndeid,text_response):\n",
    "    dictlist = []\n",
    "    records = text_response.split('\\n')\n",
    "    i=0\n",
    "    k=len(records)\n",
    "    while i<k:\n",
    "        results = records[i].split('\\t')\n",
    "        dictlist.append({'_id':ndeid,'extracted_text':results[0],'entity_type':results[1],'onto_id':results[2]})\n",
    "        i = i+1\n",
    "    return dictlist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd439e3b",
   "metadata": {},
   "source": [
    "## Generate the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "afcde26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201222\n",
      "CPU times: total: 172 ms\n",
      "Wall time: 1.74 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## Perform the initial query\n",
    "\n",
    "#query_url = 'https://api.data.niaid.nih.gov/v1/query?q=_exists_:species&fields=_id,name,species&fetch_all=true'\n",
    "query_url = 'https://api-staging.data.niaid.nih.gov/v1/query?q=_exists_:species&fields=_id,name,description&fetch_all=true'\n",
    "r = requests.get(query_url)\n",
    "cleanr = json.loads(r.text)\n",
    "hits = cleanr['hits']\n",
    "#print(len(cleanr['hits']))\n",
    "df1 = pd.DataFrame(cleanr['hits'])\n",
    "scroll_id = cleanr['_scroll_id']\n",
    "total_hits = cleanr['total']\n",
    "print(total_hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e2a0c590",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'_scroll_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:10\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '_scroll_id'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Scroll to get all the results\n",
    "\n",
    "i = 0\n",
    "#k = 3 \n",
    "k = math.ceil(total_hits/1000)\n",
    "while i < k:\n",
    "    #r2 = requests.get(f'https://api.data.niaid.nih.gov/v1/query?scroll_id={scroll_id}')\n",
    "    r2 = requests.get(f'https://api-staging.data.niaid.nih.gov/v1/query?scroll_id={scroll_id}')\n",
    "    tmp = json.loads(r2.text)\n",
    "    scroll_id = tmp['_scroll_id']\n",
    "    tmpdf = pd.DataFrame(tmp['hits'])\n",
    "    df1 = pd.concat((df1,tmpdf),ignore_index=True)\n",
    "    #print(len(df1))\n",
    "    i = i+1\n",
    "    time.sleep(0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "57847646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201222\n",
      "                    _id  _score  \\\n",
      "0  DDE_0565c31a11705723     1.0   \n",
      "1  DDE_095ecd25213286dd     1.0   \n",
      "2  DDE_1058e9acef861126     1.0   \n",
      "\n",
      "                                         description  \\\n",
      "0  Metabolomics data from cell culture; Treated w...   \n",
      "1  APMS analysis of SARS-CoV-2 proteins to evalua...   \n",
      "2  We performed genome-wide CRISPR KO screens in ...   \n",
      "\n",
      "                                                name _ignored  \n",
      "0  Primary human microvascular endothelial cells ...      NaN  \n",
      "1     Protein-protein interaction map for SARS-CoV-2      NaN  \n",
      "2  genotyping by high throughput sequencing, gene...      NaN  \n"
     ]
    }
   ],
   "source": [
    "## Inspect and save the results of the search\n",
    "\n",
    "print(len(df1))\n",
    "print(df1.head(n=3))\n",
    "with open(os.path.join(script_path,'data','processed_species_results.pickle'),'wb') as dumpfile:\n",
    "    pickle.dump(df1,dumpfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad167f5",
   "metadata": {},
   "source": [
    "## Perform one test inquiry for EXTRACT API\n",
    "\n",
    "Determine how the query needs be made and how to parse the reponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0aafadaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  _id                                           raw_text  \\\n",
      "0  OMICSDI_PRJNA13120  Mycoplasma hyopneumoniae 232| The causative ag...   \n",
      "1  OMICSDI_PRJNA13401  Spiroplasma citri| The causative agent of Citr...   \n",
      "\n",
      "  source  \n",
      "0    NDE  \n",
      "1    NDE  \n"
     ]
    }
   ],
   "source": [
    "colnames = ['_id', 'raw_text','source']\n",
    "unannotated_records = pd.read_csv(input_file,delimiter='\\t',names=colnames)\n",
    "print(unannotated_records.head(n=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cc6e1197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mycoplasma+hyopneumoniae+232.+The+causative+agent+of+swine+mycoplasmosis.\n"
     ]
    }
   ],
   "source": [
    "base_url = f\"http://tagger.jensenlab.org/GetEntities?document={raw_text}&entity_types=-2+-26&format=tsv\"\n",
    "\n",
    "test_text = unannotated_records.iloc[0]['raw_text'].replace('|','.').replace(' ','+')\n",
    "print(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "adccd6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = test_text\n",
    "r = requests.get(base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5981fdd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['swine\\t-2\\t9823', 'Mycoplasma hyopneumoniae 232\\t-2\\t295358']\n"
     ]
    }
   ],
   "source": [
    "print(r.text.split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2b695a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': 'OMICSDI_PRJNA13120', 'extracted_text': 'swine', 'entity_type': '-2', 'onto_id': '9823'}, {'_id': 'OMICSDI_PRJNA13120', 'extracted_text': 'Mycoplasma hyopneumoniae 232', 'entity_type': '-2', 'onto_id': '295358'}]\n"
     ]
    }
   ],
   "source": [
    "result = parse_tsv('OMICSDI_PRJNA13120',r.text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebeadf1",
   "metadata": {},
   "source": [
    "## Conduct test Extraction test\n",
    "\n",
    "#### extract entities for which species data is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e3fdf994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    _id  _score  \\\n",
      "0  DDE_0565c31a11705723     1.0   \n",
      "1  DDE_095ecd25213286dd     1.0   \n",
      "\n",
      "                                         description  \\\n",
      "0  Metabolomics data from cell culture; Treated w...   \n",
      "1  APMS analysis of SARS-CoV-2 proteins to evalua...   \n",
      "\n",
      "                                                name _ignored  \n",
      "0  Primary human microvascular endothelial cells ...      NaN  \n",
      "1     Protein-protein interaction map for SARS-CoV-2      NaN  \n",
      "201222\n"
     ]
    }
   ],
   "source": [
    "print(df1.head(n=2))\n",
    "print(len(df1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ec9346b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    _id  _score  \\\n",
      "0  DDE_0565c31a11705723     1.0   \n",
      "1  DDE_095ecd25213286dd     1.0   \n",
      "\n",
      "                                         description  \\\n",
      "0  Metabolomics data from cell culture; Treated w...   \n",
      "1  APMS analysis of SARS-CoV-2 proteins to evalua...   \n",
      "\n",
      "                                                name _ignored  \\\n",
      "0  Primary human microvascular endothelial cells ...      NaN   \n",
      "1     Protein-protein interaction map for SARS-CoV-2      NaN   \n",
      "\n",
      "                                            raw_text  \n",
      "0  Primary human microvascular endothelial cells ...  \n",
      "1  Protein-protein interaction map for SARS-CoV-2...  \n"
     ]
    }
   ],
   "source": [
    "df1['raw_text'] = df1['name'].astype(str).str.cat(df1['description'].astype(str),sep='. ').replace('\\n',' ')\n",
    "print(df1.head(n=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0e426031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "              _id  _score                                        description  \\\n",
      "116846  GSE238109     1.0  To elucidate the role of bta-miR-484 in adipoc...   \n",
      "146350  GSE185888     1.0  This SuperSeries is composed of the SubSeries ...   \n",
      "\n",
      "                                                     name       _ignored  \\\n",
      "116846  RNA-Seq analyses in bta-miR-484 transfected ad...  [all.keyword]   \n",
      "146350  ALKBH5 promotes tumor progression by decreasin...            NaN   \n",
      "\n",
      "                                                 raw_text  \n",
      "116846  RNA-Seq analyses in bta-miR-484 transfected ad...  \n",
      "146350  ALKBH5 promotes tumor progression by decreasin...  \n"
     ]
    }
   ],
   "source": [
    "testdf = df1.sample(10000,replace=False)\n",
    "print(len(testdf))\n",
    "print(testdf.head(n=2))\n",
    "with open(os.path.join(script_path,'data','test_10000_data.pickle'),'wb') as writefile:\n",
    "    pickle.dump(testdf,writefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a38aa7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed\n",
      "failed\n",
      "failed\n",
      "failed\n",
      "failed\n",
      "failed\n",
      "failed\n",
      "failed\n",
      "failed\n",
      "failed\n",
      "CPU times: total: 14min 6s\n",
      "Wall time: 19h 28min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "n = 49300\n",
    "m = len(testdf)\n",
    "#m=10\n",
    "extractlist = []\n",
    "faillist = []\n",
    "while n < m:\n",
    "    raw_text = testdf.iloc[n]['raw_text'].replace(' ','+').strip('\\n').replace('\\n','+')\n",
    "    base_url = f\"http://tagger.jensenlab.org/GetEntities?document={raw_text}&entity_types=-2&format=tsv\"\n",
    "    r = requests.get(base_url)\n",
    "    if r.status_code == 200:\n",
    "        if len(r.text)>0:\n",
    "            try:\n",
    "                tmpdf = parse_tsv(testdf.iloc[n]['_id'],r.text)\n",
    "                extractlist.extend(tmpdf)\n",
    "            except:\n",
    "                faillist.append({\"_id\":testdf.iloc[n]['_id'],\"fail_type\":\"reponse_parse_fail\"})\n",
    "    else:\n",
    "        print('failed')\n",
    "        time.sleep(0.25)\n",
    "        faillist.append({\"_id\":testdf.iloc[n]['_id'],\"fail_type\":\"request_fail\"})\n",
    "    n = n+1\n",
    "    time.sleep(0.25)\n",
    "\n",
    "#print(extractlist)\n",
    "testresultdf = pd.DataFrame(extractlist)\n",
    "cleanresult = testresultdf.loc[(testresultdf['entity_type']==-2)|(testresultdf['entity_type']=='-2')]\n",
    "cleanresult.to_csv(os.path.join(script_path,'data','test_100000.tsv'),sep='\\t',header=0)\n",
    "with open(os.path.join(script_path,'data','test_100000_fails.pickle'),'wb') as failfile:\n",
    "    pickle.dump(faillist,failfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d2d46f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48630\n",
      "659\n"
     ]
    }
   ],
   "source": [
    "testresultdf = pd.DataFrame(extractlist)\n",
    "print(len(testresultdf['_id'].unique().tolist()))\n",
    "print(len(faillist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e9ab0e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanresult = testresultdf.loc[(testresultdf['entity_type']==-2)|(testresultdf['entity_type']=='-2')]\n",
    "cleanresult.to_csv(os.path.join(script_path,'data','test_50000.tsv'),sep='\\t',header=0)\n",
    "with open(os.path.join(script_path,'data','test_50000_fails.pickle'),'wb') as failfile:\n",
    "    pickle.dump(faillist,failfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "41f7f4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?><GetEntitiesResponse xmlns=\"Reflect\" xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"><items><item><name xsi:type=\"xsd:string\">Eed</name><count xsi:type=\"xsd:int\">1</count><entities><entity><type xsi:type=\"xsd:int\">9606</type><identifier xsi:type=\"xsd:string\">ENSP00000263360</identifier></entity><entity><type xsi:type=\"xsd:int\">10090</type><identifier xsi:type=\"xsd:string\">ENSMUSP00000102853</identifier></entity></entities></item></items></GetEntitiesResponse>\n"
     ]
    }
   ],
   "source": [
    "print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "73103940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            _id                           extracted_text entity_type onto_id\n",
      "0     GSE157915                      Xenopus allofraseri          -2  288535\n",
      "1     GSE216370                                     mice          -2   10090\n",
      "5       GSE6738                                    human          -2    9606\n",
      "7      GSE47404                                    Human          -2    9606\n",
      "10    GSE108656                                    human          -2    9606\n",
      "...         ...                                      ...         ...     ...\n",
      "3375   GSE61171                                    human          -2    9606\n",
      "3377  GSE122058  Salmonella enterica serovar Typhimurium          -2   90371\n",
      "3378  GSE122058                               Salmonella          -2     590\n",
      "3379  GSE122058                                    human          -2    9606\n",
      "3381   GSE59780                                    human          -2    9606\n",
      "\n",
      "[1721 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(cleanresult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5247fcc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': 'GSE135638', 'fail_type': 'reponse_parse_fail'}, {'_id': 'GSE143561', 'fail_type': 'reponse_parse_fail'}, {'_id': 'GSE160524', 'fail_type': 'reponse_parse_fail'}, {'_id': 'GSE137164', 'fail_type': 'reponse_parse_fail'}, {'_id': 'GSE133658', 'fail_type': 'reponse_parse_fail'}, {'_id': 'GSE106301', 'fail_type': 'reponse_parse_fail'}, {'_id': 'GSE74550', 'fail_type': 'reponse_parse_fail'}, {'_id': 'GSE97411', 'fail_type': 'reponse_parse_fail'}, {'_id': 'GSE50679', 'fail_type': 'reponse_parse_fail'}, {'_id': 'GSE10838', 'fail_type': 'reponse_parse_fail'}, {'_id': 'GSE230628', 'fail_type': 'reponse_parse_fail'}, {'_id': 'GSE109509', 'fail_type': 'reponse_parse_fail'}, {'_id': 'GSE125653', 'fail_type': 'reponse_parse_fail'}, {'_id': 'GSE147326', 'fail_type': 'reponse_parse_fail'}, {'_id': 'GSE85696', 'fail_type': 'reponse_parse_fail'}, {'_id': 'GSE147895', 'fail_type': 'reponse_parse_fail'}, {'_id': 'GSE155605', 'fail_type': 'reponse_parse_fail'}]\n"
     ]
    }
   ],
   "source": [
    "print(faillist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea90c96b",
   "metadata": {},
   "source": [
    "## Evaluate the results\n",
    "\n",
    "1. Run Text2Term for all the extracted raw text (to be able to compare with Extract)\n",
    "2. If an extracted raw text term mapped to multiple species, select the one with the best score (Text2Term), since Extract does not give scores, select the one that appears more than once in the paragraph\n",
    "3. Compare the results with those pulled from PubTator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bd14acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210242\n",
      "         _id extracted_term  extracted_type  taxid           CURIE\n",
      "0  GSE238109         bovine              -2   9913  NCBITAXON:9913\n",
      "1  GSE187829          human              -2   9606  NCBITAXON:9606\n"
     ]
    }
   ],
   "source": [
    "## load the results from Extract\n",
    "\n",
    "df1 = pd.read_csv(os.path.join(output_path, 'test_49000.tsv'), delimiter='\\t',header=None, index_col=0)\n",
    "df2 = pd.read_csv(os.path.join(output_path, 'test_50000.tsv'), delimiter='\\t',header=None, index_col=0)\n",
    "dfall = pd.concat((df1,df2), ignore_index=True)\n",
    "dfall.rename(columns={1:'_id',2:'extracted_term',3:'extracted_type',4:'taxid'},inplace=True)\n",
    "dfall['CURIE'] = ['NCBITAXON:'+str(x) for x in dfall['taxid']]\n",
    "\n",
    "print(len(dfall))\n",
    "print(dfall.head(n=2))\n",
    "dfall.to_csv(os.path.join(output_path, 'test_100000.tsv'), sep='\\t', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0832af09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78630\n",
      "131612\n",
      "78630\n",
      "                    _id   extracted_term  extracted_type  counts  taxid  \\\n",
      "0  DDE_01a3d57e683d1471  West Nile virus              -2       1  11082   \n",
      "1  DDE_01a3d57e683d1471          viruses              -2       1  10239   \n",
      "\n",
      "             CURIE  \n",
      "0  NCBITAXON:11082  \n",
      "1  NCBITAXON:10239  \n",
      "131612\n"
     ]
    }
   ],
   "source": [
    "## deal with multimapped results\n",
    "dfgrouped = dfall.groupby(['_id','extracted_term','extracted_type']).size().reset_index(name='counts')\n",
    "dfgrpunique = dfgrouped.loc[dfgrouped['counts']==1]\n",
    "print(len(dfunique))\n",
    "\n",
    "dfgrpmulti = dfgrouped.loc[dfgrouped['counts']!=1]\n",
    "print(len(dfmulti))\n",
    "\n",
    "dfunique = dfgrpunique.merge(dfall,on=['_id','extracted_term','extracted_type'],how='left')\n",
    "print(len(dfunique))\n",
    "print(dfunique.head(n=2))\n",
    "\n",
    "dfmulti = dfgrpmulti.merge(dfall,on=['_id','extracted_term','extracted_type'],how='left')\n",
    "print(len(dfmulti))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e3806e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    _id  _score  \\\n",
      "0  DDE_0565c31a11705723     1.0   \n",
      "1  DDE_095ecd25213286dd     1.0   \n",
      "\n",
      "                                                name  \\\n",
      "0  Primary human microvascular endothelial cells ...   \n",
      "1     Protein-protein interaction map for SARS-CoV-2   \n",
      "\n",
      "                                             species _ignored           CURIE  \n",
      "0  {'alternateName': ['Human', 'Homo sapiens Linn...      NaN  NCBITAXON:9606  \n",
      "1  {'alternateName': ['Human', 'Homo sapiens Linn...      NaN  NCBITAXON:9606  \n"
     ]
    }
   ],
   "source": [
    "## load the Pubtator Results\n",
    "speciespubtatordf = pd.read_csv(os.path.join(parent_path,'text2term_test','data','clean_pubtator_results_from_nde.tsv'),delimiter='\\t',header=0,index_col=0)\n",
    "infectpubtatordf = pd.read_csv(os.path.join(parent_path,'text2term_test','data','infectiousAgent_clean_pubtator_results_from_nde.tsv'),delimiter='\\t',header=0,index_col=0)\n",
    "infectpubtatordf.rename(columns={'infectiousAgent':'species'}, inplace=True)\n",
    "pubtatordf = pd.concat((speciespubtatordf,infectpubtatordf), ignore_index=True)\n",
    "print(pubtatordf.head(n=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "23115bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78630\n",
      "                    _id   extracted_term  extracted_type  counts  taxid  \\\n",
      "0  DDE_01a3d57e683d1471  West Nile virus              -2       1  11082   \n",
      "1  DDE_01a3d57e683d1471          viruses              -2       1  10239   \n",
      "\n",
      "             CURIE  _score                                               name  \\\n",
      "0  NCBITAXON:11082     1.0  Mouse popliteal lymph node transcriptome respo...   \n",
      "1  NCBITAXON:10239     NaN                                                NaN   \n",
      "\n",
      "                                             species _ignored  \n",
      "0  {'alternateName': ['WNV'], 'classification': '...      NaN  \n",
      "1                                                NaN      NaN  \n",
      "41383\n",
      "                    _id   extracted_term  extracted_type  counts    taxid  \\\n",
      "0  DDE_01a3d57e683d1471  West Nile virus              -2       1    11082   \n",
      "2  DDE_095ecd25213286dd       SARS-CoV-2              -2       1  2697049   \n",
      "\n",
      "               CURIE  _score  \\\n",
      "0    NCBITAXON:11082     1.0   \n",
      "2  NCBITAXON:2697049     1.0   \n",
      "\n",
      "                                                name  \\\n",
      "0  Mouse popliteal lymph node transcriptome respo...   \n",
      "2     Protein-protein interaction map for SARS-CoV-2   \n",
      "\n",
      "                                             species _ignored  \n",
      "0  {'alternateName': ['WNV'], 'classification': '...      NaN  \n",
      "2  {'alternateName': ['2019-nCoV', 'Wuhan coronav...      NaN  \n",
      "37247\n"
     ]
    }
   ],
   "source": [
    "## See how many of the terms that mapped to a single species by EXTRACT mapped to Pubtator species\n",
    "\n",
    "dfunique_merged = dfunique.merge(pubtatordf,on=['_id','CURIE'],how='left')\n",
    "print(len(dfunique_merged))\n",
    "print(dfunique_merged.head(n=2))\n",
    "dfunique_matched = dfunique_merged.loc[~dfunique_merged['species'].isna()]\n",
    "dfunique_unmatched = dfunique_merged.loc[dfunique_merged['species'].isna()]\n",
    "## number of matching mappings\n",
    "print(len(dfunique_matched))\n",
    "print(dfunique_matched.head(n=2))\n",
    "\n",
    "## number of unmatched mappings\n",
    "print(len(dfunique_unmatched))\n",
    "## these are EXTRACT-based mappings that did not match because\n",
    "#### 1. The mapping from EXTRACT is wrong OR\n",
    "#### 2. EXTRACT pulled out more terms to map than was available from Pubtator via PMID matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6109d7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    _id extracted_term  extracted_type  counts  taxid  \\\n",
      "0  DDE_01a3d57e683d1471          Mouse              -2       2  10090   \n",
      "1  DDE_01a3d57e683d1471          Mouse              -2       2  10088   \n",
      "2  DDE_01a3d57e683d1471          mouse              -2       2  10090   \n",
      "3  DDE_01a3d57e683d1471          mouse              -2       2  10088   \n",
      "\n",
      "             CURIE  \n",
      "0  NCBITAXON:10090  \n",
      "1  NCBITAXON:10088  \n",
      "2  NCBITAXON:10090  \n",
      "3  NCBITAXON:10088  \n"
     ]
    }
   ],
   "source": [
    "## Inspect the case when EXTRACT maps a single term to multiple taxa\n",
    "print(dfmulti.head(n=4))\n",
    "#### Since EXTRACT does not do any sort of scoring, better to use Text2Term\n",
    "#### See Text2Term test notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f082eb",
   "metadata": {},
   "source": [
    "## Check the results from Dylan's tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "575e8818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': 'veupathdb_DS_cd1a65bcca', 'extracted_text': 'Anopheles gambiae s', 'entity_type': '-2', 'onto_id': '7165'}, {'_id': 'veupathdb_DS_cd1a65bcca', 'extracted_text': 'Anopheles gambiae', 'entity_type': '-2', 'onto_id': '7165'}]\n"
     ]
    }
   ],
   "source": [
    "text = \"First report of the East African kdr mutation in an Anopheles gambiae mosquito in Côte d’Ivoire| Immature stages of Anopheles gambiae s.l. were collected from breeding sites at the outskirts of Yamoussoukro, Côte d'Ivoire. Emerging 3-5 day old adult female mosquitoes were tested for susceptibility to deltamethrin 0.05%, malathion 5%, bendiocarb 1% and dichlorodiphenyltrichloroethane (DDT) 4% according to WHO standard procedures. A total of 50  An. gambiae s.l. specimens were drawn at random for DNA extraction and identification down to the species level. A subsample of 30 mosquitoes was tested for the East-African kdr mutation using a Taqman assay. (MapVEu VBP0000191)\"\n",
    "test_text = text.replace('|','.').replace(' ','+')\n",
    "base_url = f\"http://tagger.jensenlab.org/GetEntities?document={test_text}&entity_types=-2&format=tsv\"\n",
    "\n",
    "r = requests.get(base_url)\n",
    "result = parse_tsv('veupathdb_DS_cd1a65bcca',r.text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e354ad",
   "metadata": {},
   "source": [
    "## Dealing with location terms that map to taxa\n",
    "\n",
    "There are a handful of country, U.S. state names that have exact matches in NCBI taxon. However, the probability of a dataset being about that particular taxon (vs being mentioned as a location) should be relatively low. To address this, we will create an exclusion list by using Wikidata queries to pull names of sovereign states and U.S. States and using EXTRACT to map these to NCBI taxon. This way, we can identify the location terms that EXTRACT will likely pull out as species.\n",
    "\n",
    "**additional information**\n",
    "Wikidata: \n",
    "* Sovereign state: Q3624078\n",
    "* U.S. state: Q35657\n",
    "\n",
    "Example query 1: \"https://query.wikidata.org/#%23Countries%0ASELECT%20%3Fitem%20%3FitemLabel%20%0AWHERE%20%0A%7B%0A%20%20%3Fitem%20wdt%3AP31%20wd%3AQ3624078.%20%23%20Must%20be%20a%20sovereign%20state%0A%20%20SERVICE%20wikibase%3Alabel%20%7B%20bd%3AserviceParam%20wikibase%3Alanguage%20%22%5BAUTO_LANGUAGE%5D%2Cen%22.%20%7D%20%23%20Helps%20get%20the%20label%20in%20your%20language%2C%20if%20not%2C%20then%20en%20language%0A%7D\"\n",
    "\n",
    "Example query 2: \"https://query.wikidata.org/#%23US%20states%0ASELECT%20%3Fitem%20%3FitemLabel%20%0AWHERE%20%0A%7B%0A%20%20%3Fitem%20wdt%3AP31%20wd%3AQ35657.%20%23%20Must%20be%20a%20US%20state%0A%20%20SERVICE%20wikibase%3Alabel%20%7B%20bd%3AserviceParam%20wikibase%3Alanguage%20%22%5BAUTO_LANGUAGE%5D%2Cen%22.%20%7D%20%23%20Helps%20get%20the%20label%20in%20your%20language%2C%20if%20not%2C%20then%20en%20language%0A%7D\"\n",
    "\n",
    "Rather than trying to parse the overly-complicated Wikidata json files, the query results were downloaded as tsv files via the browser interface and saved to the data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0174b04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  item   itemLabel\n",
      "0   http://www.wikidata.org/entity/Q99  California\n",
      "1  http://www.wikidata.org/entity/Q173     Alabama\n",
      "                                 item itemLabel\n",
      "0  http://www.wikidata.org/entity/Q16    Canada\n",
      "1  http://www.wikidata.org/entity/Q17     Japan\n"
     ]
    }
   ],
   "source": [
    "states = pd.read_csv(os.path.join(output_path,'state_query_results.tsv'), delimiter='\\t',header=0)\n",
    "print(states.head(n=2))\n",
    "countries = pd.read_csv(os.path.join(output_path,'country_query_results.tsv'), delimiter='\\t',header=0)\n",
    "print(countries.head(n=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ff3090a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['California', 'Alabama', 'Maine', 'New Hampshire', 'Massachusetts', 'Connecticut', 'Hawaii', 'Alaska', 'Florida', 'Arizona', 'Oregon', 'Utah', 'Michigan', 'Illinois', 'North Dakota', 'South Dakota', 'Montana', 'Wyoming', 'Idaho', 'Washington', 'Nevada', 'Colorado', 'Virginia', 'West Virginia', 'New York', 'Rhode Island', 'Maryland', 'Delaware', 'Ohio', 'Pennsylvania', 'New Jersey', 'Indiana', 'Georgia', 'Texas', 'North Carolina', 'South Carolina', 'Mississippi', 'Tennessee', 'New Mexico', 'Minnesota', 'Wisconsin', 'Iowa', 'Nebraska', 'Kansas', 'Missouri', 'Louisiana', 'Kentucky', 'Arkansas', 'Oklahoma', 'Vermont']\n",
      " California Alabama Maine New Hampshire Massachusetts Connecticut Hawaii Alaska Florida Arizona Oregon Utah Michigan Illinois North Dakota South Dakota Montana Wyoming Idaho Washington Nevada Colorado Virginia West Virginia New York Rhode Island Maryland Delaware Ohio Pennsylvania New Jersey Indiana Georgia Texas North Carolina South Carolina Mississippi Tennessee New Mexico Minnesota Wisconsin Iowa Nebraska Kansas Missouri Louisiana Kentucky Arkansas Oklahoma Vermont\n",
      "      _id extracted_text entity_type onto_id\n",
      "0  states         Nevada          -2  359889\n",
      "1  states        Montana          -2  441235\n"
     ]
    }
   ],
   "source": [
    "## extract the lists\n",
    "statelist = states['itemLabel'].unique().tolist()\n",
    "print(statelist)\n",
    "raw_text = \"\"\n",
    "for eachstate in statelist:\n",
    "    raw_text = raw_text+\" \"+(eachstate)\n",
    "\n",
    "print(raw_text)\n",
    "base_url = f\"http://tagger.jensenlab.org/GetEntities?document={raw_text}&entity_types=-2+-26&format=tsv\"\n",
    "r = requests.get(base_url)\n",
    "dictlist = parse_tsv('states',r.text)\n",
    "statedf = pd.DataFrame(dictlist)\n",
    "print(statedf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f8de78da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " China\n",
      " Canada Japan Norway  Ireland Hungary Spain United States of America Belgium Luxembourg Finland Sweden Poland Lithuania Italy Switzerland Austria Greece Turkey Portugal Uruguay Egypt Mexico Kenya Ethiopia Ghana France United Kingdom  China Brazil Russia Germany Belarus Iceland Estonia Latvia Ukraine Czech  Slovakia Slovenia Moldova Romania Bulgaria North Macedonia Albania Croatia Bosnia and Herzegovina Azerbaijan Andorra Cyprus Georgia Kazakhstan Malta Monaco Montenegro Vatican City San Marino Cuba Belize Barbados Indonesia South Africa Algeria Uzbekistan Chile Singapore Liechtenstein Bahrain Armenia Serbia Australia Argentina Peru North Korea Cambodia East Timor Chad New Zealand India Tuvalu Tonga Samoa Solomon Islands Vanuatu Papua New Guinea Palau Nauru Federated States of Micronesia Marshall Islands Kiribati Mongolia Fiji Venezuela Suriname Paraguay Guyana Ecuador Colombia Bolivia Trinidad and Tobago Saint Vincent and the Grenadines  Geneva Saint Lucia Saint Kitts and Nevis Jamaica Grenada Guatemala The Bahamas Antigua and Barbuda Honduras Dominica Dominican  Haiti El Salvador Iran Iraq Costa Rica Israel Panama Yemen Jordan Nicaragua Kyrgyzstan Kuwait Laos Lebanon Maldives Malaysia Myanmar Nepal Oman Pakistan Qatar Saudi Arabia Sri Lanka Syria Tajikistan Taiwan Thailand Turkmenistan United Arab Emirates Vietnam South Korea Afghanistan Bangladesh Mali Angola Bhutan Brunei Tanzania Philippines Central African  Togo Tunisia Zambia Zimbabwe South Sudan Benin Botswana Burkina Faso Burundi Comoros  Congo   Congo Djibouti Equatorial Guinea Eritrea Gabon The Gambia Guinea Guinea-Bissau Ivory Coast Cameroon Cape Verde Lesotho Liberia Libya Madagascar Malawi Mauritania Mauritius Morocco Mozambique Namibia Niger Nigeria Uganda Rwanda São Tomé and Príncipe Senegal Seychelles Sierra Leone Somalia Sudan Eswatini  the Netherlands  Palestine  Denmark Serendip Q12891054 Q13100640 Unyasa\n",
      "       _id extracted_text entity_type onto_id\n",
      "0  country          Tonga          -2  130597\n"
     ]
    }
   ],
   "source": [
    "def clean_stopwords(termtext):\n",
    "    stopwordlist = [\"People's Republic of\",\"State of\",\"Kingdom of\", \"Republic of the\", \"Republic of\",\"Republic\",\"Democratic\"]\n",
    "    for eachword in stopwordlist:\n",
    "        termtext = termtext.replace(eachword,\"\")\n",
    "    return termtext\n",
    "\n",
    "print(clean_stopwords(\"People's Republic of China\"))\n",
    "\n",
    "countrylist = countries['itemLabel'].unique().tolist()\n",
    "raw_text = \"\"\n",
    "for eachcountry in countrylist:\n",
    "    cleancountry = clean_stopwords(eachcountry)\n",
    "    raw_text = raw_text+\" \"+(cleancountry)\n",
    "\n",
    "print(raw_text)\n",
    "base_url = f\"http://tagger.jensenlab.org/GetEntities?document={raw_text}&entity_types=-2+-26&format=tsv\"\n",
    "r = requests.get(base_url)\n",
    "dictlist = parse_tsv('country',r.text)\n",
    "countrydf = pd.DataFrame(dictlist)\n",
    "print(countrydf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13c7bfe",
   "metadata": {},
   "source": [
    "Based on the results above, the only Country and state names that EXTRACT will accidentally pull as species terms are:\n",
    "`Montana`, `Nevada`, and `Tonga`\n",
    "\n",
    "It did not pull out the term `China` even though `China` has an exact match in NCBI Taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb79ab6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
